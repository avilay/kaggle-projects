{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93f36ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from higgs.consts import COLNAMES, DATAROOT\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57b50346",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c1f90dc3cba2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m np.set_printoptions(\n\u001b[1;32m      5\u001b[0m     \u001b[0medgeitems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 30\n",
    "\n",
    "np.set_printoptions(\n",
    "    edgeitems=30, \n",
    "    linewidth=100000, \n",
    "    precision=3,\n",
    "    suppress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f662a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = DATAROOT / \"SAMPLE_HIGGS.csv\"\n",
    "higgs = pd.read_csv(filename, header=None, names=COLNAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5102685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "higgs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4700a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_size = int(len(higgs) * 0.9)\n",
    "valset_size = len(higgs) - trainset_size\n",
    "print(f\"trainset size: {trainset_size:,}, valset size: {valset_size:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba8d000",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_df = higgs[:trainset_size]\n",
    "valset_df = higgs[trainset_size:]\n",
    "print(f\"trainset size: {len(trainset_df)}, valset size: {len(valset_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170cf05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PandasDataset(td.Dataset):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self._X = df[COLNAMES[1:]].values\n",
    "        self._y = df[\"label\"].values.astype(int)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._y.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self._X[idx], self._y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88aa72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = PandasDataset(trainset_df)\n",
    "valset = PandasDataset(valset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db4a30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiggsDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, dataroot=DATAROOT, infile=\"SAMPLE_HIGGS.csv\", trainset_prop=0.9, hp=None):\n",
    "        super().__init__()\n",
    "        self.trainset, self.valset = None, None\n",
    "        self.hparams = hp\n",
    "        self._dataroot = dataroot\n",
    "        self._infile = infile\n",
    "        self._trainset_prop = trainset_prop\n",
    "        self._trainfile = self._dataroot / \"train.pkl\"\n",
    "        self._valfile = self._dataroot / \"val.pkl\"\n",
    "        \n",
    "    def prepare(self):\n",
    "        if (self._trainfile.exists() and self._valfile.exists()):\n",
    "            return\n",
    "            \n",
    "        higgs = pd.read_csv(self._filename, header=None, names=COLNAMES)\n",
    "        \n",
    "        trainset_size = int(len(higgs) * self._trainset_prop)\n",
    "        train_df = higgs[:trainset_size]\n",
    "        train_X = train_df[COLNAMES[1:]].values\n",
    "        train_y = train_df[\"label\"].values.astype(int)\n",
    "        with open(self.trainfile, \"wb\") as f:\n",
    "            pickle.dump(f, {\"X\": train_X, \"y\": train_y})\n",
    "        \n",
    "        valset_size = len(higgs) - trainset_size\n",
    "        val_df = higgs[trainset_size:]\n",
    "        val_X = val_df[COLNAMES[1:]].values\n",
    "        val_y = val_df[\"label\"].values.astype(int)\n",
    "        with open(self._valfile, \"wb\") as f:\n",
    "            pickle.dump(f, {\"X\": val_X, \"y\": val_y})\n",
    "        \n",
    "    def setup(self, stage):\n",
    "        if stage == \"fit\":\n",
    "            \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
